{\rtf1\ansi\ansicpg1251\deff0\nouicompat\deflang1058{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.16299}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 In this segment, let's discuss the process\par
of statistical thinking using two examples\par
from a current news event.\par
The first example is a sample survey.\par
In September 2015, Gallup Poll released their current finding\par
on Americans' perception of the job market.\par
It is a simple survey conducted using data\par
from 1,025 randomly selected Americans answering questions\par
in a telephone survey.\par
In the survey, one of the questions\par
is, is it a good time to find a job in the current job market?\par
And the results from the survey shows\par
that 51% of the respondents reported that it is a bad time\par
to find a job, while 45% of the respondents\par
think it's a good time to find a job.\par
4% of respondents didn't give their answer for this question.\par
Also included in the release of the results\par
is a statistical statement that says\par
that the margin of error for the results\par
is 4% for the 95% percent confidence interval.\par
Throughout the course of this module,\par
we'll discuss the meaning of the terminology used in this\par
statement, such as margin of error and the meaning\par
of the two numbers quoted here-- the 4% and the 95%--\par
and what is a confidence interval\par
in terms of a statistical estimation.\par
So now, let's think about the results released the survey\par
as a statistician.\par
The first question is, what was the study trying to find out?\par
As indicated by the title of the study,\par
the study is trying to find out about a population\par
of interest--\par
Americans-- and a variable interest,\par
which is their perception of the job market.\par
So if this is the goal of the study,\par
here comes our next question.\par
Why should we care about the sample of 1,025 Americans\par
selected for this study, and about their opinion reported\par
in a sample survey?\par
Another way of asking this question\par
is whether these 1,025 survey participants\par
can represent the entire population\par
of 300 million Americans.\par
The answer to this question is yes and no.\par
First, this 1,025 survey participants\par
will be, in some way, different from some of the individuals\par
in the population.\par
So they cannot really fully represent the entire\par
population.\par
On the other hand, because they're randomly\par
selected from population, the overall trend in the population\par
is represented by this random sample,\par
so that we can study this random sample\par
to gauge the overall opinion trend occurring\par
in the entire population.\par
So here comes the first message for statistical thinking,\par
is statistics derives knowledge from sample regarding\par
the population by carefully conducted collection and data\par
analysis.\par
The second example is a clinical trial.\par
This is also very interesting news\par
we heard about in September 2015,\par
and it's about a study called SPRINT.\par
So if you search for SPRINT blood pressure study,\par
you will a lot of media coverage on this event.\par
The reason for that is the findings of this study\par
can potentially change the medical recommendations\par
on blood pressure control.\par
For the purpose of our example, that we only need to know\par
this is a systolic blood pressure intervention trial.\par
It's a clinical trial sponsored by the National\par
Institute of Health.\par
So first, let's discuss how the study is being carried out.\par
This is a simplified version of the study\par
we constructed using the brief description of the study\par
from the news release.\par
The study concerns a population of individuals.\par
So they first look at defining what they're trying to study.\par
The population they want to study\par
is patients who are 50 years old,\par
or order, at an increased risk of heart disease and/or kidney\par
disease.\par
So this is a large population.\par
We do not have the resources or time\par
to study the entire population.\par
So therefore, we need to select a small set of individuals\par
to carry out the comparison of different treatments.\par
So here, the first step of the study is recruitment.\par
The recruitment is done through more than 100 medical centers\par
and clinical practices to derive a diverse sample of women,\par
minority, and elderly.\par
The reason for that, as we'll discuss later,\par
is different individuals in the population\par
may have different probability of being\par
selected if the sample is carried out randomly.\par
So therefore, to create a more representative sample,\par
sometimes we need to design sampling strategies\par
to have better coverage.\par
So after this requirement, we need\par
derive a small set of individuals who\par
will participate in the study--\par
about 9,300 of them.\par
After the recruitment, our focus will\par
be on these 9,300 participants instead\par
of the entire population out there,\par
even though our conclusion will hopefully\par
be applicable to the entire population under study.\par
The design of study is summarized as following\par
in this simplified diagram.\par
You have 9,300 participants.\par
The first step after the start of the study\par
is random assignments.\par
So you will assign these 9,300 participants\par
into two groups randomly.\par
The first group is a treatment group.\par
The second group is a control group.\par
And these two groups are created so that they're similar,\par
except for differences due to chance.\par
The reason why they may be different\par
is these 9,300 are all different.\par
They're all individuals.\par
They all have their own environmental factors,\par
demographic background, and their individual profiles.\par
They have different values for age, for height, for weight,\par
for health habits, for their occupation risks,\par
so on and so forth.\par
So they're all different.\par
In the random assignment they will\par
be randomly put in treatment group and control group.\par
Therefore, the two groups will have some random differences\par
because they have different individuals.\par
Then, after the group assignments,\par
the two groups of individuals will\par
receive different treatments.\par
In the treatment group, you will receive a new targeted level\par
of blood pressure control.\par
In the control group, you will receive a conventional target\par
level of blood pressure control.\par
In this study, this target level of blood pressure control\par
are achieved using a whole array of medical assistance.\par
So that is not part of the difference between the two\par
groups.\par
The difference between the two groups\par
is their targeted level of blood pressure.\par
So after a certain period of treatments,\par
we will observe and measure the health results\par
from the two groups, and then we'll compare them.\par
Then we will observe some differences,\par
because these two different individuals received\par
two different treatments.\par
So now the scientific question, and the question\par
for the statistician who will analyze this data,\par
is whether this difference can be explained purely by chance.\par
Can we observe difference in health results,\par
even these two treatments have no difference in effects.\par
Can this different be purely explained by chance?\par
So here comes the second exercise\par
of statistical thinking, as we have just\par
discussed in the example of the SPRINT blood pressure study.\par
Here we have input, which is the different treatments and blood\par
pressure management, and we want to study its true effect\par
on the output, which is the health results based\par
on blood pressure control.\par
But at the same time, we know that there\par
are other random factors that may\par
have random effects on the outcome,\par
such as the age of the participants, the other health\par
habits and occupation risks, and the environmental factors\par
that could potentially affect the outcome.\par
So our question is, as a statistician,\par
how do we carry out the statistical inference\par
so that we can estimate the extent of the random effects,\par
and then use that to establish the size of the true effect?\par
And the other way to say this exercise\par
is, how we evaluate the observed effect\par
so that we can say whether it is likely to occur\par
purely by chance?\par
That whether is it possible the two groups look\par
different because they started off,\par
after the random assignment as different groups,\par
then they will exhibit different health results\par
at the end of the study-- whether we can observe that.\par
If it's very unlikely to observe a certain level of differences,\par
we will call it statistically significant.\par
Which is a way of saying that the effect is so big that we\par
do not think that it can be explained purely by chance,\par
and we believe part of it is due to a really\par
true existing true effect from the treatments.\par
So that is statistical thinking number two.\par
That statisticians using statistical method\par
establishes the statistical significance of observed signal\par
by studying randomness.\par
So this is why, in the course of this module\par
and the next module, we'll study the law of probabilities,\par
which is a field of mathematics that studies randomness.\par
Let's discuss how we derive good answers from observed data.\par
So we always want to work on some data at hand\par
to derive good answers about question we may have.\par
Data is generated from a data generating process.\par
In some studies we have some control\par
over how the data is generated.\par
But more often than not, we do not\par
have control over the generating process,\par
such as in an observational study.\par
Statisticians and data scientists\par
make assumptions about the data generating process.\par
These assumptions will guide us in deciding\par
what analysis we should use for this particular data.\par
Then we feed the data through the analysis process\par
to derive answers to our questions,\par
such as knowledge about certain system,\par
the business intelligence, and the solutions about a question\par
we're interested in.\par
If the assumption we make about data generating process\par
is not valid, then the answers will become invalid.\par
What should we do when this happens?\par
We need to investigate, in particular,\par
what assumptions we made was invalid,\par
and then we will come up with revisions to the assumptions.\par
These revisions to the assumptions\par
will lead to revisions in our analysis plan,\par
and hopefully that resolves the issue\par
with the assumption regarding the data generating process,\par
then give us good answers to our questions.\par
So this will be a repeated process\par
throughout the entire research in data science,\par
and we constantly want to investigate whether we're\par
making the right assumption about the data generating\par
process because we want to generate good answers\par
from the data collected.\par
So here, one of the message people\par
often bring up in data science is whether we have garbage in\par
and garbage out.\par
This phrase is referring to the phenomenon\par
that, if the data were not collected carefully\par
that will contain a lot of the biases,\par
and you use an existing method to analyze\par
the data without realizing the biases,\par
then your answer will be biased.\par
So the validity of results depends\par
on the validity of assumptions we make on the data generating\par
process.\par
Such assumptions include assumptions on sampling,\par
randomization, the measurements of the data,\par
and independence between variables, and so forth.\par
So they are often violated for big data,\par
because the big data accumulated very quickly\par
without a lot of human control over the data generating\par
process.\par
And because of that, we need to investigate these assumptions\par
in relation to the data collected\par
and propose creative solutions.\par
In one of the modules in this course,\par
Professor David Madigan will describe\par
some phenomenons observed in observed health data,\par
and the solution they proposed to create revised data\par
analysis in relation to the observational health studies.\par
End of transcript. Skip to the start.\par
Downloads and transcripts\par
Handouts\par
}
 