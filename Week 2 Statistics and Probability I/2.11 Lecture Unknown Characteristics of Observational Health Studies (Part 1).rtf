{\rtf1\ansi\ansicpg1251\deff0\nouicompat\deflang1058{\fonttbl{\f0\fnil\fcharset0 Calibri;}}
{\*\generator Riched20 10.0.16299}\viewkind4\uc1 
\pard\sa200\sl276\slmult1\f0\fs22\lang9 So what have we learned from these examples?\par
And as I've said, these are just a few examples\par
of many hundreds of examples I could have given you like this.\par
So what are we learning?\par
Well, we're certainly learning that there's a problem here.\par
That when we conduct these kinds of studies,\par
that very easily we come up with conflicting results.\par
Certainly, when you analyze two different databases,\par
they can be conflicting.\par
But perhaps even more disturbingly,\par
when you have different groups of people\par
analyzing the same data, they can\par
arrive at opposite conclusions.\par
So I would claim that in actual fact, when we do these studies,\par
the operating characteristics are unknown.\par
Now, operating characteristics.\par
What do I mean by operating characteristics\par
in this context?\par
Well, so in those papers that we were just looking at,\par
a key, or the key, the sort of centerpiece\par
of the results of those papers is a numerical estimate\par
of the effect of the drug.\par
So for example, for the oral bisphosphonates and cancer\par
of the esophagus, the very first paper that we looked at.\par
In that particular paper, the estimated relative risk\par
of cancer of the esophagus associated\par
with oral bisphosphonates was 1.3.\par
So that's an estimated relative--\par
that's the best guess from that study as to what\par
the relative risk is.\par
And in this particular case, it's a 30% increased risk.\par
So one would interpret this to mean\par
when you take oral bisphosphonates, your risk\par
of cancer of the esophagus goes up\par
by 30% as against the background risk\par
had you not taken oral bisphosphonates.\par
So that's the estimated relative risk.\par
Estimated-- the point estimate in the jargon.\par
Estimated-- I'll just do RR, relative risk.\par
But crucially, what's also provided\par
in the paper, associated with this estimated relative risk,\par
is a 95% confidence interval.\par
And in that particular paper, the interval\par
goes from 1.02 to 1.66.\par
So this is a 95%-- I just put CI-- confidence interval.\par
And the idea of this interval is that it's\par
meant to capture our uncertainty about the true relative risk.\par
So we know from the study, our guess\par
is the point estimate of the true relative risk is 1.3.\par
But with a finite amount of data,\par
we acknowledge that it might be off\par
from the true relative risk.\par
And this interval is meant to capture our uncertainty\par
about the true relative risk.\par
Crucially, in this particular case,\par
the interval does not include one.\par
So the interval is entirely above one.\par
And that's synonymous with this phrase,\par
statistical significance.\par
So we're confident in some sense that the true relative risk,\par
while we're not entirely sure what\par
it is, we're confident that it's bigger than one.\par
That there really is an elevated risk here.\par
So this 95% interval is very important.\par
So if instead this interval-- supposing\par
it hadn't gone from 1.02 to 1.06.\par
Supposing instead the interval went from 0.2 to 3.2,\par
which might have been the case, if that\par
had been the 95% confidence interval,\par
we would have a very different interpretation of the results.\par
So now we'd be saying, we think there's a 30% increased risk,\par
but with some degree of confidence,\par
this risk could be anywhere from 0.2, which is well\par
below one, which would say that the drugs are actually having\par
a preventative effect on cancer of the esophagus,\par
to a very substantially increased, more\par
than a threefold increased risk.\par
So the interval is very important in our interpretation\par
of the studies.\par
So what do we mean when we say we have a 95% confidence\par
interval?\par
Well, let me try and explain what the concept is here.\par
So let me draw a relative risk scale.\par
And I'll do this roughly on a log scale.\par
So a relative risk of 1, would correspond to no risk at all.\par
The same risk on the drug as not on the drug.\par
And let's go, say down here is 0.5.\par
And then we've got 2.\par
And so on up here.\par
Maybe 3 up here.\par
So the particular interval that was\par
in that paper, the first paper that we looked at,\par
the point estimate was about 1.3.\par
And the interval went from just below 1--\par
I'll do it this way-- to 1.66.\par
So the interval looked like that.\par
So the idea is of this, when we say 95% confidence interval,\par
is had we done this exercise over and over again,\par
or rather every time we do this exercise,\par
we produce a confidence interval.\par
95% of the intervals that we might have produced had we\par
replicated the whole thing should\par
contain the true relative risk.\par
So if the 95% confidence intervals,\par
for example, looked like this.\par
And here's another one that we might have gotten\par
had we replicated the study.\par
Here's another one.\par
Here's another one.\par
So it should be the case-- I won't keep drawing them.\par
It should be the case that wherever\par
the true relative risk is-- which we don't know what it is.\par
But let's imagine for argument's sake\par
that the true relative risk is here.\par
It should be the case that 95% of these intervals--\par
in this particular case, three of the four\par
that I drew-- but more generally, 95% of the intervals\par
should contain the true relative-- the true or known\par
relative risk.\par
And 5% of them should not.\par
So it is the case that some of the intervals,\par
precisely 5% of them, should not contain the truth.\par
So that's what we mean when we talk about a 95% confidence\par
interval.\par
I said earlier on that I claim that these methods have\par
unknown operating characteristics.\par
And by that I mean the following.\par
Supposing it's the case that the methods we're using here\par
produce intervals that contain the truth much less than 95%\par
of the time.\par
So supposing these are the kinds of intervals\par
that these methods produce.\par
Some of them contain the truth, but many of them do not.\par
So in this particular case, we've got 1, 2, 3, 4, 5, 6, 7,\par
8, 9, 10 intervals.\par
It should be the case that 9 or 10 of them\par
contain the truth and 0 or 1 of them\par
does not contain the truth.\par
And in this particular case, as you\par
can see the way I've drawn it, of the 10 intervals,\par
1, 2, 3, 4, 5 do not contain the truth.\par
So in this particular case, if this\par
is the way our method worked in practice, if this\par
is what was its behavior when we used this method, instead\par
of having a 95% coverage probability, instead\par
our method would have a 50% coverage probability.\par
That's very different.\par
If it is the case that our method produces intervals that\par
only contain the truth 50% of the time, what we're saying\par
is we don't have a very reliable way of generating evidence.\par
Many of the intervals don't contain the truth at all.\par
It's nowhere near 95%.\par
So the textbooks-- mathematically,\par
if you're under certain assumptions,\par
the methods should have 95% coverage.\par
But in actual fact, because of various problems\par
with these data, measurement error, biases\par
due to unmeasured confounding, biases\par
due to selection of patients of a particular type\par
into the database, and on and on and on-- there\par
are many threats to the validity of these studies--\par
we don't actually know what the coverage probability is.\par
Maybe it's 95%.\par
That would be great.\par
But maybe it's 50%.\par
In which case, when we publish these papers,\par
we're essentially deluding ourselves by thinking that we\par
have strong evidence when, in fact, we don't.\par
End of transcript. Skip to the start.\par
  Previous\par
}
 